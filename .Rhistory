shiny::runApp()
shiny::runApp()
library(tidyverse)
#load datasets
residence <- read_csv('data/police_residence.csv')
cities <- read_csv('data/cities.csv')
demographics <- read_delim('data/us-cities-demographics.csv', delim = ';')
killings <- read_csv('data/police_killings.csv')
hate_crimes <- read_csv('data/hate_crimes.csv')
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')))
cities <- cities %>%
mutate(city = str_to_lower(CITY), lat = LATITUDE, lon = LONGITUDE, state_code = STATE_CODE) %>%
select(c('city', 'lat', 'lon', state_code))
dups <- duplicated(cities %>% select(c('city', 'state_code')))
cities <- cities %>%
filter(!dups)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
rename_with(.cols = everything(), .fn = str_replace, ' ', '_') %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#extract number of police killings in each city
killings_by_city <- killings %>%
mutate(city = str_to_lower(city)) %>%
group_by(city, state) %>%
summarize(killings = n())
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
select(-c('count_NA', 'race_prop_NA'))
write_csv(joined_cities, 'data/joined_cities.csv')
residence
#load datasets
residence <- read_csv('data/police_residence.csv',
col_types = cols(black = col_double(),
hispanic = col_doubl(),
asian = col_double()))
#load datasets
residence <- read_csv('data/police_residence.csv',
col_types = cols(black = col_double(),
hispanic = col_double(),
asian = col_double()))
?accross
?across
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')),
across(.cols = c('black', 'hispanic', 'asian'), .fns = coalesce, 0.0))
cities <- cities %>%
mutate(city = str_to_lower(CITY), lat = LATITUDE, lon = LONGITUDE, state_code = STATE_CODE) %>%
select(c('city', 'lat', 'lon', state_code))
dups <- duplicated(cities %>% select(c('city', 'state_code')))
cities <- cities %>%
filter(!dups)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
rename_with(.cols = everything(), .fn = str_replace, ' ', '_') %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#extract number of police killings in each city
killings_by_city <- killings %>%
mutate(city = str_to_lower(city)) %>%
group_by(city, state) %>%
summarize(killings = n())
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
select(-c('count_NA', 'race_prop_NA'))
rf_data <- joined_cities %>%
mutate(had_killing = killings > 0) %>%
select(-c('city', 'state_code', 'state', 'killings'))
library(tidyverse)
#load datasets
residence <- read_csv('data/police_residence.csv',
col_types = cols(black = col_double(),
hispanic = col_double(),
asian = col_double()))
cities <- read_csv('data/cities.csv')
demographics <- read_delim('data/us-cities-demographics.csv', delim = ';')
killings <- read_csv('data/police_killings.csv')
hate_crimes <- read_csv('data/hate_crimes.csv')
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')),
across(.cols = c('black', 'hispanic', 'asian'), .fns = coalesce, 0.0))
cities <- cities %>%
mutate(city = str_to_lower(CITY), lat = LATITUDE, lon = LONGITUDE, state_code = STATE_CODE) %>%
select(c('city', 'lat', 'lon', state_code))
dups <- duplicated(cities %>% select(c('city', 'state_code')))
cities <- cities %>%
filter(!dups)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
rename_with(.cols = everything(), .fn = str_replace, ' ', '_') %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#extract number of police killings in each city
killings_by_city <- killings %>%
mutate(city = str_to_lower(city)) %>%
group_by(city, state) %>%
summarize(killings = n())
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
select(-c('count_NA', 'race_prop_NA'))
write_csv(joined_cities, 'data/joined_cities.csv')
#find which variables are most important for predicting killings
set.seed(2347904)
rf_data <- joined_cities %>%
mutate(had_killing = killings > 0) %>%
select(-c('city', 'state_code', 'state', 'killings'))
View(rf_data)
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 10)
#find which variables are most important for predicting killings
library(randomForest)
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 10)
rf_data <- joined_cities %>%
mutate(had_killing = killings > 0) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 10)
rf_data
?rename
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')),
across(.cols = c('black', 'hispanic', 'asian'), .fns = coalesce, 0.0)) %>%
rename(nonwhite = `non-white`)
library(tidyverse)
#load datasets
residence <- read_csv('data/police_residence.csv',
col_types = cols(black = col_double(),
hispanic = col_double(),
asian = col_double()))
cities <- read_csv('data/cities.csv')
demographics <- read_delim('data/us-cities-demographics.csv', delim = ';')
killings <- read_csv('data/police_killings.csv')
hate_crimes <- read_csv('data/hate_crimes.csv')
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')),
across(.cols = c('black', 'hispanic', 'asian'), .fns = coalesce, 0.0)) %>%
rename(nonwhite = `non-white`)
cities <- cities %>%
mutate(city = str_to_lower(CITY), lat = LATITUDE, lon = LONGITUDE, state_code = STATE_CODE) %>%
select(c('city', 'lat', 'lon', state_code))
dups <- duplicated(cities %>% select(c('city', 'state_code')))
cities <- cities %>%
filter(!dups)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
rename_with(.cols = everything(), .fn = str_replace, ' ', '_') %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#extract number of police killings in each city
killings_by_city <- killings %>%
mutate(city = str_to_lower(city)) %>%
group_by(city, state) %>%
summarize(killings = n())
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
select(-c('count_NA', 'race_prop_NA'))
rf_data <- joined_cities %>%
mutate(had_killing = killings > 0) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 10)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
rename_with(.cols = everything(), .fn = str_replace_all, ' ', '_') %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
select(-c('count_NA', 'race_prop_NA'))
View(demographics)
library(tidyverse)
#load datasets
residence <- read_csv('data/police_residence.csv',
col_types = cols(black = col_double(),
hispanic = col_double(),
asian = col_double()))
cities <- read_csv('data/cities.csv')
demographics <- read_delim('data/us-cities-demographics.csv', delim = ';')
killings <- read_csv('data/police_killings.csv')
hate_crimes <- read_csv('data/hate_crimes.csv')
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')),
across(.cols = c('black', 'hispanic', 'asian'), .fns = coalesce, 0.0)) %>%
rename(nonwhite = `non-white`)
cities <- cities %>%
mutate(city = str_to_lower(CITY), lat = LATITUDE, lon = LONGITUDE, state_code = STATE_CODE) %>%
select(c('city', 'lat', 'lon', state_code))
dups <- duplicated(cities %>% select(c('city', 'state_code')))
cities <- cities %>%
filter(!dups)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#extract number of police killings in each city
killings_by_city <- killings %>%
mutate(city = str_to_lower(city)) %>%
group_by(city, state) %>%
summarize(killings = n())
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
rename_with(.cols = everything(), .fn = str_replace_all, ' ', '_') %>%
select(-c('count_NA', 'race_prop_NA'))
write_csv(joined_cities, 'data/joined_cities.csv')
library(tidyverse)
#load datasets
residence <- read_csv('data/police_residence.csv',
col_types = cols(black = col_double(),
hispanic = col_double(),
asian = col_double()))
cities <- read_csv('data/cities.csv')
demographics <- read_delim('data/us-cities-demographics.csv', delim = ';')
killings <- read_csv('data/police_killings.csv')
hate_crimes <- read_csv('data/hate_crimes.csv')
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')),
across(.cols = c('black', 'hispanic', 'asian'), .fns = coalesce, 0.0)) %>%
rename(nonwhite = `non-white`)
cities <- cities %>%
mutate(city = str_to_lower(CITY), lat = LATITUDE, lon = LONGITUDE, state_code = STATE_CODE) %>%
select(c('city', 'lat', 'lon', state_code))
dups <- duplicated(cities %>% select(c('city', 'state_code')))
cities <- cities %>%
filter(!dups)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
rename_with(.cols = everything(), .fn = str_replace_all, ' ', '_') %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#extract number of police killings in each city
killings_by_city <- killings %>%
mutate(city = str_to_lower(city)) %>%
group_by(city, state) %>%
summarize(killings = n())
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
rename_with(.cols = everything(), .fn = str_replace_all, ' ', '_') %>%
select(-c('count_NA', 'race_prop_NA'))
write_csv(joined_cities, 'data/joined_cities.csv')
rf_data <- joined_cities %>%
mutate(had_killing = killings > 0) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 10)
library(tidyverse)
#load datasets
residence <- read_csv('data/police_residence.csv',
col_types = cols(black = col_double(),
hispanic = col_double(),
asian = col_double()))
cities <- read_csv('data/cities.csv')
demographics <- read_delim('data/us-cities-demographics.csv', delim = ';')
killings <- read_csv('data/police_killings.csv')
hate_crimes <- read_csv('data/hate_crimes.csv')
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')),
across(.cols = c('black', 'hispanic', 'asian'), .fns = coalesce, 0.0))
cities <- cities %>%
mutate(city = str_to_lower(CITY), lat = LATITUDE, lon = LONGITUDE, state_code = STATE_CODE) %>%
select(c('city', 'lat', 'lon', state_code))
dups <- duplicated(cities %>% select(c('city', 'state_code')))
cities <- cities %>%
filter(!dups)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
rename_with(.cols = everything(), .fn = str_replace_all, ' ', '_') %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#extract number of police killings in each city
killings_by_city <- killings %>%
mutate(city = str_to_lower(city)) %>%
group_by(city, state) %>%
summarize(killings = n())
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
rename_with(.cols = everything(), .fn = str_replace_all, '( |-)', '_') %>%
select(-c('count_NA', 'race_prop_NA'))
write_csv(joined_cities, 'data/joined_cities.csv')
#find which variables are most important for predicting killings
library(randomForest)
rf_data <- joined_cities %>%
mutate(had_killing = killings > 0) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 10)
#find which variables are most important for predicting killings
library(caret)
library(tidyverse)
#load datasets
residence <- read_csv('data/police_residence.csv',
col_types = cols(black = col_double(),
hispanic = col_double(),
asian = col_double()))
cities <- read_csv('data/cities.csv')
demographics <- read_delim('data/us-cities-demographics.csv', delim = ';')
killings <- read_csv('data/police_killings.csv')
hate_crimes <- read_csv('data/hate_crimes.csv')
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')),
across(.cols = c('black', 'hispanic', 'asian'), .fns = coalesce, 0.0))
cities <- cities %>%
mutate(city = str_to_lower(CITY), lat = LATITUDE, lon = LONGITUDE, state_code = STATE_CODE) %>%
select(c('city', 'lat', 'lon', state_code))
dups <- duplicated(cities %>% select(c('city', 'state_code')))
cities <- cities %>%
filter(!dups)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
rename_with(.cols = everything(), .fn = str_replace_all, ' ', '_') %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#extract number of police killings in each city
killings_by_city <- killings %>%
mutate(city = str_to_lower(city)) %>%
group_by(city, state) %>%
summarize(killings = n())
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
rename_with(.cols = everything(), .fn = str_replace_all, '( |-)', '_') %>%
select(-c('count_NA', 'race_prop_NA'))
write_csv(joined_cities, 'data/joined_cities.csv')
#find which variables are most important for predicting killings
library(caret)
set.seed(2347904)
knn_data <- joined_cities %>%
mutate(had_killing = killings > 0) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
k <- seq(1, length(knn_data), by = 2)
train_control <- trainControl(method = "cv", number = 10)
killings_rf <- randomForest(had_killing ~ . , data = knn_data, mtry = 10)
varImpPlot(spam_rf, n.var = 10)
library(randomForest)
killings_rf <- randomForest(had_killing ~ . , data = knn_data, mtry = 10)
mutate(had_killing = as.factor(ifelse(killings > 0, 'yes', 'no')) %>%
drop_na()
knn_data <- joined_cities %>%
mutate(had_killing = as.factor(ifelse(killings > 0, 'yes', 'no')) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
)
drop_na()
knn_data <- joined_cities %>%
mutate(had_killing = as.factor(ifelse(killings > 0, 'yes', 'no'))) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
View(knn_data)
levels(knn_data$had_killing)
knn_data <- joined_cities %>%
mutate(had_killing = as.factor(ifelse(killings > 0, 'yes', 'no')),
had_killing = fct_relevel(had_killing, 'yes')) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
levels(knn_data$had_killing)
killings_rf <- randomForest(had_killing ~ . , data = knn_data, mtry = 10)
library(varImpPlot)
varImpPlot(killings_rf, n.var = 10)
varImpPlot(killings_rf, n.var = 15)
predict(killings_rf, newdata = rf_data)
rf_data <- joined_cities %>%
mutate(had_killing = as.factor(ifelse(killings > 0, 'yes', 'no')),
had_killing = fct_relevel(had_killing, 'yes')) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
predict(killings_rf, newdata = rf_data)
predict(killings_rf, newdata = rf_data)[1]
predict(killings_rf, newdata = rf_data)[1] == 'yes'
library(tidyverse)
#load datasets
residence <- read_csv('data/police_residence.csv',
col_types = cols(black = col_double(),
hispanic = col_double(),
asian = col_double()))
cities <- read_csv('data/cities.csv')
demographics <- read_delim('data/us-cities-demographics.csv', delim = ';')
killings <- read_csv('data/police_killings.csv')
hate_crimes <- read_csv('data/hate_crimes.csv')
#standardize variables across geographical data sets for joining
residence <- residence %>%
mutate(city = str_to_lower(str_extract(residence$city, '[^,]+(?=(,|$))')),
across(.cols = c('black', 'hispanic', 'asian'), .fns = coalesce, 0.0))
cities <- cities %>%
mutate(city = str_to_lower(CITY), lat = LATITUDE, lon = LONGITUDE, state_code = STATE_CODE) %>%
select(c('city', 'lat', 'lon', state_code))
dups <- duplicated(cities %>% select(c('city', 'state_code')))
cities <- cities %>%
filter(!dups)
demographics <- demographics %>%
rename_with(str_to_lower) %>%
rename_with(.cols = everything(), .fn = str_replace_all, ' ', '_') %>%
mutate(across(.cols = c('city', 'race'), .fns = str_to_lower))
#extract number of police killings in each city
killings_by_city <- killings %>%
mutate(city = str_to_lower(city)) %>%
group_by(city, state) %>%
summarize(killings = n())
#join location and demographic data to police residence data for all cities in residence
joined_cities <- residence %>%
left_join(cities, by = c('city', 'state_code')) %>%
left_join(demographics, by = c('city', 'state_code')) %>%
left_join(killings_by_city, by = c('city', 'state_code' = 'state')) %>%
mutate(killings = coalesce(killings, 0),
race_prop = count / total_population,
police_force_prop = police_force_size / total_population) %>%
pivot_wider(names_from = race, values_from = c('count', 'race_prop')) %>%
rename_with(.cols = everything(), .fn = str_replace_all, '( |-)', '_') %>%
select(-c('count_NA', 'race_prop_NA'))
write_csv(joined_cities, 'data/joined_cities.csv')
#find which variables are most important for predicting killings
library(caret)
library(randomForest)
library(varImpPlot)
set.seed(2347904)
rf_data <- joined_cities %>%
mutate(had_killing = as.factor(ifelse(killings > 0, 'yes', 'no')),
had_killing = fct_relevel(had_killing, 'yes')) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
train_control <- trainControl(method = "cv", number = 10)
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 10)
varImpPlot(killings_rf, n.var = 15)
varImpPlot(killings_rf, n.var = 20) #it looks like police force size, average household size, and the proportion of all police that live in the city are important
?varImpPlot
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 7)
varImpPlot(killings_rf, n.var = 20) #it looks like police force size, average household size, and the proportion of all police that live in the city are important
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 15)
varImpPlot(killings_rf, n.var = 20) #it looks like police force size, average household size, and the proportion of all police that live in the city are important
killings_rf <- randomForest(had_killing ~ . , data = rf_data, mtry = 20)
varImpPlot(killings_rf, n.var = 20) #it looks like police force size, average household size, and the proportion of all police that live in the city are important
shiny::runApp()
runApp()
rf_var_plot <- varImpPlot(killings_rf_all, n.var = 15, main = 'City Stats Most Influential to Classification')
#fit preliminary rf model with all variables
rf_data <- joined_cities %>%
mutate(had_killing = as.factor(ifelse(killings > 0, 'yes', 'no')),
had_killing = fct_relevel(had_killing, 'yes')) %>%
select(-c('city', 'state_code', 'state', 'killings')) %>%
drop_na()
killings_rf_all <- randomForest(had_killing ~ . , data = rf_data, mtry = 14)
rf_var_plot <- varImpPlot(killings_rf_all, n.var = 15, main = 'City Stats Most Influential to Classification')
View(rf_var_plot)
type(rf_var_plot)
typeof(rf_var_plot)
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
